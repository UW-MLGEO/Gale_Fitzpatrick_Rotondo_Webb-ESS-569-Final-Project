{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "422b4e28",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initial Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926ffbb9",
   "metadata": {},
   "source": [
    "\n",
    "### Description:\n",
    "This section covers data loading and any preprocessing steps needed before model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f783097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading time for 'sst' variable: 0.09865999221801758 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import xarray as xr\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the dataset\n",
    "ds = xr.open_dataset('/Users/Joey/Downloads/ready_sic_sst_data.nc') # change me to be the path to the file on your computer\n",
    "\n",
    "# Explicitly load the 'sst' variable\n",
    "sst_data = ds['sst'].load()  # .load() forces data into memory for accurate timing\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Data loading time for 'sst' variable: {end_time - start_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbe328f",
   "metadata": {},
   "source": [
    "## 2. Training Time Analysis\n",
    "\n",
    "### Description:\n",
    "In this section, analyze the training time for various model architectures. Measure the time taken to train each model configuration, and evaluate how different parameters (e.g., batch size, epochs, layers) impact training speed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7ff614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "# Convert to a DataFrame for use in model training\n",
    "df = sst_data.to_dataframe().reset_index()\n",
    "\n",
    "# Remove any rows with NaN values if necessary\n",
    "df = df.dropna()\n",
    "\n",
    "# Define target variable if applicable (e.g., 'target' column)\n",
    "# Ensure your dataset has a target variable for supervised learning.\n",
    "target_column = 'sst'  # Replace with actual target column name\n",
    "\n",
    "# Example: Using subsets of SST features based on spatial or temporal resolutions.\n",
    "# Here we'll assume 'sst' is a single feature for simplicity.\n",
    "\n",
    "# Different feature configurations based on data availability\n",
    "feature_configs = [\n",
    "    df.columns[:10],  # If there are 10 SST features or fewer (dummy example)\n",
    "    df.columns[:20],  # If 20 features are needed\n",
    "    df.columns        # All available SST features\n",
    "]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "import time\n",
    "\n",
    "# Function to evaluate time vs. accuracy trade-offs\n",
    "def evaluate_accuracy_vs_time(df, features, target_column, model_type=RandomForestRegressor):\n",
    "    # Filter data for the selected features\n",
    "    X = df[features]\n",
    "    y = df[target_column]\n",
    "    \n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Instantiate model and track time\n",
    "    model = model_type()\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Evaluate accuracy\n",
    "    predictions = model.predict(X_test)\n",
    "    accuracy = r2_score(y_test, predictions)\n",
    "    training_time = end_time - start_time\n",
    "    \n",
    "    return accuracy, training_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a7413d",
   "metadata": {},
   "source": [
    "## 3. Accuracy vs. Time Trade-Off\n",
    "### Description:\n",
    "Evaluate the trade-off between training time and model accuracy for different configurations. This helps in understanding the balance between computational cost and model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abe7feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "# Evaluate each feature configuration\n",
    "for config in feature_configs:\n",
    "    accuracy, time_taken = evaluate_accuracy_vs_time(df, config, target_column='target')\n",
    "    results.append({'features': len(config), 'accuracy': accuracy, 'time': time_taken})\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Plot Accuracy vs. Time\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(results_df['time'], results_df['accuracy'], marker='o')\n",
    "plt.title(\"Accuracy vs. Time Trade-off for SST Data\")\n",
    "plt.xlabel(\"Time (seconds)\")\n",
    "plt.ylabel(\"Accuracy (RÂ² score)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644337ec",
   "metadata": {},
   "source": [
    "## 4. Deployment Time Estimation\n",
    "### Description:\n",
    "Estimate the computational time requirements for deploying the model in real-world scenarios. This includes model loading, inference time, and overall latency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17836e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Measure inference time for deployment\n",
    "import time\n",
    "\n",
    "# model = load_model('best_model.h5')\n",
    "sample_data = None  # Replace with a sample input, such as Barents-Kara sea\n",
    "# Select data for Barents-Kara Sea region\n",
    "#sample_data = ds.sel(latitude=slice('85.01', '65'), longitude=slice('30', '90.01'))\n",
    "# sample_data\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "# model.predict(sample_data)  # Run inference\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Inference time: {end_time - start_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9245e6",
   "metadata": {},
   "source": [
    "## 5. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52dd9e17",
   "metadata": {},
   "source": [
    "### Summary of Findings\n",
    "\n",
    "Based on this analysis, here are some potential conclusions comparing the **Decision Tree Regressor**, **Random Forest Regressor**, and **Linear Regression** for the `sst` data:\n",
    "\n",
    "### 1. **Random Forest Regressor**\n",
    "   - **Accuracy**: The Random Forest Regressor generally provides the highest accuracy among the three models due to its ability to reduce overfitting by averaging over multiple trees. This allows it to capture complex patterns in the `sst` data, which is especially beneficial for data with intricate relationships.\n",
    "   - **Computational Time**: Training time for the Random Forest is higher compared to simpler models like a single Decision Tree or Linear Regression due to the need to train multiple trees. However, this increase in time is often justified by the significant gain in accuracy.\n",
    "   - **Conclusion**: Random Forest is an excellent choice when high accuracy is essential, and the computational resources are available to handle the longer training times.\n",
    "\n",
    "### 2. **Decision Tree Regressor**\n",
    "   - **Accuracy**: Decision Trees perform slightly less accurately than Random Forests, as they tend to overfit individual trees and do not benefit from the averaging effect that reduces variance. However, Decision Trees still capture non-linear relationships in the data well, making them a strong choice for moderately complex datasets.\n",
    "   - **Computational Time**: Decision Trees require significantly less training time than Random Forests because only a single tree is built, making them suitable when computational efficiency is prioritized without sacrificing too much accuracy.\n",
    "   - **Conclusion**: Decision Trees strike a good balance between accuracy and time, providing a high-accuracy alternative to Random Forests with reduced computational demands. This is particularly useful when resources are limited, or training speed is critical.\n",
    "\n",
    "### 3. **Linear Regression**\n",
    "   - **Accuracy**: Linear Regression, being a simple model, often underperforms on complex datasets like `sst` data where relationships are likely non-linear and high-dimensional. Its assumptions of linearity limit its ability to accurately capture the intricacies of `sst` patterns.\n",
    "   - **Computational Time**: Linear Regression has the shortest training time since it only fits a single linear model without requiring tree construction or ensemble averaging. This simplicity, however, comes at the cost of lower predictive accuracy.\n",
    "   - **Conclusion**: Linear Regression might be acceptable if interpretability and speed are prioritized over accuracy. However, the accuracy trade-off is substantial, making it a less favorable choice for complex datasets.\n",
    "\n",
    "### Overall Conclusion\n",
    "In summary:\n",
    "\n",
    "- **Random Forest Regressor** is ideal when accuracy is paramount, and the slightly higher computational cost can be accommodated.\n",
    "- **Decision Tree Regressor** offers a middle ground, delivering a reasonable accuracy similar to Random Forests but with shorter training times, making it a more computationally efficient alternative.\n",
    "- **Linear Regression** sacrifices too much accuracy for speed, and its simplicity does not justify its use on complex `sst` data.\n",
    "\n",
    "Thus, the **Decision Tree Regressor** provides a compelling trade-off, capturing a good amount of data complexity without the extensive computational cost of Random Forests."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NERSC Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
